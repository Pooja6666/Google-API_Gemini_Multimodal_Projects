{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install google-generativeai    #pip install generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd95a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c27d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b313b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gemini_api_key import google_key\n",
    "os.environ[\"Ramyaa\"] = google_key\n",
    "\n",
    "Ramyaa = google_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a27d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.configure(api_key = Ramyaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c830be43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-exp-0801\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/aqa\n"
     ]
    }
   ],
   "source": [
    "for i in genai.list_models():\n",
    "    print(i.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25186ed0",
   "metadata": {},
   "source": [
    "## User Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbdd98c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India has **28 states** and **8 Union Territories**. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name= \"gemini-1.5-pro-latest\")\n",
    "\n",
    "user_prompt = \"How many states are present in INDIA?\"\n",
    "\n",
    "response = model.generate_content(user_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f65a60c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Chief Minister of Maharashtra in 2023 is **Eknath Shinde**. \n",
      "\n",
      "He assumed office on June 30, 2022, following a political crisis that led to the collapse of the previous government. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name= \"gemini-1.5-pro-latest\")\n",
    "\n",
    "user_prompt = \"who is cm of Maharashtra state in 2023\"\n",
    "\n",
    "response = model.generate_content(user_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887405a8",
   "metadata": {},
   "source": [
    "## System Instruction User Prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47cdfd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey buddy!  Thinking about parameters in AI, huh? It's like trying to bake the perfect cake - your ingredients are the **data**, and the **parameters** are like the recipe instructions telling the oven (the AI model) what to do with them. \n",
      "\n",
      "Let's break it down:\n",
      "\n",
      "* **Imagine a massive, complex network of knobs and dials.**  That's basically what parameters are in a generative AI model like Google's Gemini. ‚öôÔ∏è\n",
      "* **Each knob controls something specific** in how the AI processes information and learns. One knob might control how much emphasis to put on certain words, while another adjusts the relationships between different concepts. \n",
      "* **During training, the AI plays with these knobs** based on the data it's fed. It's like the AI is tasting the cake batter and constantly adjusting the recipe to get it just right. üç∞\n",
      "* **The more parameters, the more knobs and dials the AI has,** and the more subtle and complex its \"understanding\" of the data can become. üß†\n",
      "\n",
      "**So, how are these parameters used?**\n",
      "\n",
      "* **They allow the AI to generate new content.**  By tweaking the knobs based on what it's learned, it can create things like text, code, images, and even music. üé∂\n",
      "* **They help the AI understand and respond to your requests.**  When you ask it a question or give it a task, the AI uses its parameters to interpret your request and generate a relevant response. \n",
      "\n",
      "**In a nutshell:** Parameters are the secret sauce that makes generative AI so powerful. They allow the AI to learn from data and create amazing new things! üöÄ \n",
      "\n",
      "Hope that helps clear things up a bit! üëç Let me know if you have any other questions. I'm happy to chat more about AI. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name= \"gemini-1.5-pro-latest\",system_instruction = \n",
    "                              \"Hi, you are helpful as a AI assistant.user want to ask some questions about gemini generative ai model parameters.you behave like a friend\"\n",
    "                             )\n",
    "user_prompt = \"What are parameters in google generative Ai and How It is used with brief explanation for user understandable?\"\n",
    "\n",
    "response = model.generate_content(user_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddca3f49",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87230da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you're building a house. You have a huge pile of building materials: bricks, wood, nails, windows, doors, etc. But not all of them are necessary for your specific house design. You need to carefully choose the right materials to build a strong and beautiful home.\n",
      "\n",
      "Feature selection in data science is similar. It's the process of choosing the most relevant and important **features** (like the building materials) from your data to build a **model** (like your house). \n",
      "\n",
      "Here's a breakdown:\n",
      "\n",
      "**What are features?**\n",
      "\n",
      "Features are the different characteristics or variables in your data. Think of them as the columns in a spreadsheet. For example, if you're trying to predict house prices, features might include:\n",
      "\n",
      "* **Number of bedrooms**\n",
      "* **Square footage**\n",
      "* **Location**\n",
      "* **Year built**\n",
      "* **Number of bathrooms**\n",
      "\n",
      "**Why is feature selection important?**\n",
      "\n",
      "* **Improved model accuracy:** Irrelevant features can confuse your model and make it less accurate. \n",
      "* **Reduced training time:** Fewer features mean less data to process, leading to faster model training.\n",
      "* **Simpler models:** Easier to understand and interpret.\n",
      "* **Reduced risk of overfitting:** Overfitting happens when a model learns the training data too well and doesn't generalize well to new data.\n",
      "\n",
      "**How is feature selection done?**\n",
      "\n",
      "There are various techniques for feature selection, including:\n",
      "\n",
      "* **Filter methods:** These methods use statistical measures to rank features based on their importance. Examples include:\n",
      "    * **Correlation:** Measures how strongly features are related to the target variable.\n",
      "    * **Chi-square test:**  Measures the dependence between categorical features and the target variable.\n",
      "* **Wrapper methods:** These methods use a model to evaluate the performance of different feature subsets. They are more computationally expensive but can find more optimal feature sets.\n",
      "* **Embedded methods:** These methods integrate feature selection into the model building process.  Examples include:\n",
      "    * **Regularization techniques:** Penalize models with too many features.\n",
      "    * **Decision tree algorithms:**  Automatically select the most important features during tree construction.\n",
      "\n",
      "**Think of it this way:**\n",
      "\n",
      "* **Filter methods:** Like pre-sorting your building materials based on size and type.\n",
      "* **Wrapper methods:** Like trying different combinations of materials to see which ones build the strongest wall.\n",
      "* **Embedded methods:** Like using a special tool that automatically selects the right materials as you build.\n",
      "\n",
      "**In conclusion:**\n",
      "\n",
      "Feature selection is a crucial step in data science that helps you build better models by focusing on the most relevant information. By carefully selecting features, you can improve accuracy, reduce training time, and create simpler and more interpretable models. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model= genai.GenerativeModel(model_name = 'models/gemini-1.5-flash-latest')\n",
    "\n",
    "parameters = genai.types.GenerationConfig(max_output_tokens = 1000,temperature= 0.7,top_k=32,top_p=0.7)\n",
    "\n",
    "User_prompt = \"Explain me about feature selection in Data Science.to better understandable to the user\"\n",
    "\n",
    "response = model.generate_content(User_prompt,generation_config= parameters)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6634f18f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
